---
title: "ADNI Data V2 - Survival Analysis Predictive Models"
output: html_document
date: "2023-03-29"
---

# ADNI Data V3 - Survival Analysis Predictive Models - Repeated K-fold cross validation - multiple train test splits

## Install and load the relevant packages

```{r}

# install.packages("caret")
library(caret)

# install.packages("ranger")
library(ranger)

# install.packages("tidymodels")
library(tidymodels)

# install.packages("tidyverse")
library(tidyverse)

# install.packages("glmnet")
library(glmnet)

# install.packages("modeldatatoo")
library(modeldatatoo)

# install.packages("aorsf")
library(aorsf)

# install.packages("censored")
library(censored)

# install.packages("survival")
library(survival)

# install.packages("doParallel")
library(doParallel)

library(pROC) #for AUC calculation

# Set up parallel processing
registerDoParallel()
```

# Censored regression - Weibull distribution

```{r}

# Import preprocessed data 
surv_df <- read.csv("preprocessed_data.csv") 
# View(surv_df)

# Remove rows with zero survival times
surv_df <- surv_df %>% filter(VISCODE > 0)

# Check event encoding
# table(surv_df$event)

# Create survival object
surv_df1 <- surv_df %>% 
  mutate(diagnosis_surv = Surv(VISCODE, event == "1")) %>%
  select(diagnosis_surv, everything())
View(surv_df1)

# Define resampling scheme: repeated k-fold cross-validation
set.seed(403)
repeated_folds <- vfold_cv(surv_df1, v = 5, repeats = 3) # 5-fold cross-validation

# Recipe for preprocessing the data
surv_recipe <- recipe(diagnosis_surv ~ AGE + APOE4, data = surv_df1)

# Define the model: Weibull distribution survival regression
survreg_spec <- survival_reg() %>% 
  set_engine("survival") %>% 
  set_mode("censored regression")

# Create workflow combining the recipe and the model
survreg_wflow <- workflow() %>% 
  add_recipe(surv_recipe) %>% 
  add_model(survreg_spec)

# Define evaluation metrics for survival analysis
survival_metrics <- metric_set(brier_survival_integrated, brier_survival, roc_auc_survival, concordance_survival)

# Set evaluation time points for metrics
evaluation_time_points <- seq(0, 144, 6)

# Fit the model using repeated k-fold cross-validation
survreg_res <- fit_resamples(
  survreg_wflow,
  resamples = repeated_folds,
  metrics = survival_metrics,
  eval_time = evaluation_time_points,
  control = control_resamples(save_pred = TRUE)
)

#----------------------------------------------------------
# Collect and review predictions
preds <- collect_predictions(survreg_res)
print(preds) # Print the predictions to check if they are collected

# Plot the ROC AUC over time
collect_metrics(survreg_res) %>%
  filter(.metric == "roc_auc_survival") %>%
  ggplot(aes(.eval_time, mean)) +
  geom_line() +
  labs(x = "Evaluation Time (VISCODE)", y = "Area Under the ROC Curve") +
  ggtitle("weibull Distribution - Mean AUC ROC Curve Over Time")

# Plot the Brier score over time
collect_metrics(survreg_res) %>%
  filter(.metric == "brier_survival") %>%
  ggplot(aes(.eval_time, mean)) +
  geom_line() +
  labs(x = "Evaluation Time", y = "Brier Score") +
  ggtitle(" Mean weibull Distribution - Mean Brier Score Over Time")
#----------------------------------------------------------

# Unnest the predictions to extract individual predictions and fold info
preds_unnested <- survreg_res %>%
  collect_predictions() %>%
  unnest(.pred)

# Print the unnested predictions
print(preds_unnested)

#----------------------------------------------------------

# Extract metrics from the resamples object
metrics_results <- collect_metrics(survreg_res)
metrics_results

#----------------------------------------------------------

# Assuming 'metrics_results' is your data frame
# Convert the metrics data to long format if needed
metrics_long <- metrics_results %>%
  pivot_longer(cols = c(mean, std_err), names_to = "metric_type", values_to = "value")

# Create a line plot for Brier Score over evaluation time
ggplot(metrics_long %>% filter(.metric == "brier_survival"), aes(x = .eval_time, y = value, color = metric_type)) +
  geom_line() +
  labs(title = "Brier Score Over Evaluation Time",
       x = "Evaluation Time",
       y = "Brier Score",
       color = "Metric Type") +
  theme_minimal()

# Create a line plot for ROC AUC over evaluation time
ggplot(metrics_long %>% filter(.metric == "roc_auc_survival"), aes(x = .eval_time, y = value, color = metric_type)) +
  geom_line() +
  labs(title = "ROC AUC Over Evaluation Time",
       x = "Evaluation Time",
       y = "ROC AUC",
       color = "Metric Type") +
  theme_minimal()


```

-   **`.eval_time`**: The time points at which survival probabilities are evaluated.

-   **`.pred_survival`**: The predicted survival probability at each evaluation time.

-   **`.weight_censored`**: Weights that might be used for censored data.

-   **`.pred_time`**: The predicted survival time (this seems to be constant for each row).

-   **Brier Survival Integrated** (`brier_survival_integrated`): This metric assesses the overall prediction error by integrating the Brier score over the entire time span. It measures the mean squared difference between predicted survival probabilities and observed outcomes.

-   **Brier Survival** (`brier_survival`): This metric calculates the Brier score at specific time points. It measures the accuracy of probabilistic predictions by computing the mean squared error between predicted survival probabilities and actual outcomes at those time points.

-   **ROC AUC Survival** (`roc_auc_survival`): This metric computes the area under the receiver operating characteristic curve (AUC) for survival predictions. It evaluates the model's ability to discriminate between events and non-events over time.

-   **Concordance Index** (`concordance_survival`): Also known as C-index, this metric measures the concordance between predicted survival times and actual survival times. It provides an indication of how well the model ranks individuals based on their survival probabilities.

# Cox prop hazards model v2

```{r}

# Define a penalized Cox Proportional Hazards model
coxnet_spec <- proportional_hazards(penalty = tune()) %>% 
  set_engine("glmnet") %>% 
  set_mode("censored regression")

# Workflow for Cox model
coxnet_wflow <- workflow() %>% 
  add_recipe(surv_recipe) %>% 
  add_model(coxnet_spec)

# Tuning and resampling for the penalized Cox model using repeated k-fold cross-validation
set.seed(1)
coxnet_res <- tune_grid(
  coxnet_wflow,
  resamples = repeated_folds,
  grid = 10,
  metrics = survival_metrics,
  eval_time = evaluation_time_points,
  control = control_grid(save_pred = TRUE) # Ensure predictions are saved
)

# Collect and review predictions
preds <- collect_predictions(coxnet_res)
print(preds) # Print the predictions to check if they are collected

# Plot the ROC AUC over time
collect_metrics(coxnet_res) %>%
  filter(.metric == "roc_auc_survival") %>%
  ggplot(aes(.eval_time, mean)) +
  geom_line() +
  labs(x = "Evaluation Time (VISCODE)", y = "Area Under the ROC Curve") +
  ggtitle("Cox Proportional Hazards Model - AUC ROC Curve Over Time")

# Plot the Brier score over time
collect_metrics(coxnet_res) %>%
  filter(.metric == "brier_survival") %>%
  ggplot(aes(.eval_time, mean)) +
  geom_line() +
  labs(x = "Evaluation Time", y = "Brier Score") +
  ggtitle("Cox Proportional Hazards Model - Brier Score Over Time")

#----------------------------------------------------------

# Unnest the predictions to extract individual predictions and fold info
preds_unnested <- coxnet_res %>%
  collect_predictions() %>%
  unnest(.pred)

# Print the unnested predictions
print(preds_unnested)

#----------------------------------------------------------

# Extract metrics from the resamples object
metrics_results <- collect_metrics(coxnet_res)
metrics_results

#----------------------------------------------------------
```

# Random forest v2

```{r}

# Define an oblique random forest model
oblique_spec <- rand_forest(mtry = tune(), min_n = tune()) %>% 
  set_engine("aorsf") %>% 
  set_mode("censored regression")

# Workflow for oblique random forest model
oblique_wflow <- workflow() %>% 
  add_recipe(surv_recipe) %>% 
  add_model(oblique_spec)

# Define a penalized Cox Proportional Hazards model
coxnet_spec <- proportional_hazards(penalty = tune()) %>% 
  set_engine("glmnet") %>% 
  set_mode("censored regression")

# Workflow for Cox model
coxnet_wflow <- workflow() %>% 
  add_recipe(surv_recipe) %>% 
  add_model(coxnet_spec)

# Tuning and resampling for the oblique random forest model using repeated k-fold cross-validation
set.seed(1)
oblique_res <- tune_grid(
  oblique_wflow,
  resamples = repeated_folds,
  grid = 10,
  metrics = survival_metrics,
  eval_time = evaluation_time_points,
  control = control_grid(save_pred = TRUE) # Ensure predictions are saved
)

# Collect and review predictions
preds <- collect_predictions(oblique_res)
print(preds)

# Plot the ROC AUC over time
collect_metrics(oblique_res) %>%
  filter(.metric == "roc_auc_survival") %>%
  ggplot(aes(.eval_time, mean)) +
  geom_line() +
  labs(x = "Evaluation Time (VISCODE)", y = "Area Under the ROC Curve") +
  ggtitle("Random Forest - AUC ROC Curve Over Time")

# Plot the Brier score over time
collect_metrics(oblique_res) %>%
  filter(.metric == "brier_survival") %>%
  ggplot(aes(.eval_time, mean)) +
  geom_line() +
  labs(x = "Evaluation Time", y = "Brier Score") +
  ggtitle("Random Forest - Brier Score Over Time")


#----------------------------------------------------------

# Unnest the predictions to extract individual predictions and fold info
preds_unnested <- coxnet_res %>%
  collect_predictions() %>%
  unnest(.pred)

# Print the unnested predictions
print(preds_unnested)

#----------------------------------------------------------

# Extract metrics from the resamples object
metrics_results <- collect_metrics(coxnet_res)
metrics_results

#----------------------------------------------------------
```

# Comparing the 3 Models to figure out which one is the best

```{r}

# Collect and filter AUC ROC metrics
auc_data <- bind_rows(
  collect_metrics(survreg_res) %>% filter(.metric == "roc_auc_survival") %>% mutate(model = "Weibull"),
  collect_metrics(oblique_res) %>% filter(.metric == "roc_auc_survival") %>% mutate(model = "Random Forest"),
  collect_metrics(coxnet_res) %>% filter(.metric == "roc_auc_survival") %>% mutate(model = "Cox Proportional Hazards")
)

print(auc_data)


# Plot AUC ROC Over Time: Create line plots to show how the AUC ROC varies over time for each model.
ggplot(auc_data, aes(x = .eval_time, y = mean, color = model)) +
  geom_line() +
  labs(x = "Evaluation Time", y = "ROC AUC", title = "ROC AUC Curve Comparison") +
  theme_minimal()

# Boxplots of AUC ROC: Create boxplots to show the distribution of AUC ROC across folds and time points for each model.
ggplot(auc_data, aes(x = model, y = mean, fill = model)) +
  geom_boxplot() +
  labs(x = "Model", y = "ROC AUC", title = "Boxplot of ROC AUC Scores by Model") +
  theme_minimal()


# Summarize AUC ROC scores
auc_summary <- auc_data %>%
  group_by(model) %>%
  summarise(mean_auc = mean(mean),
            sd_auc = sd(mean))
print(auc_summary)

# Create a line plot of AUC ROC scores over time for each model:
ggplot(auc_data, aes(x = .eval_time, y = mean, color = model)) +
  geom_line() +
  geom_point() +
  labs(x = "Evaluation Time", y = "AUC ROC", title = "AUC ROC Over Time by Model") +
  theme_minimal()


```

```{r}

# Collect and filter Brier score metrics
brier_data <- bind_rows(
  collect_metrics(survreg_res) %>% filter(.metric == "brier_survival") %>% mutate(model = "Weibull"),
  collect_metrics(oblique_res) %>% filter(.metric == "brier_survival") %>% mutate(model = "Random Forest"),
  collect_metrics(coxnet_res) %>% filter(.metric == "brier_survival") %>% mutate(model = "Cox Proportional Hazards")
)

print(brier_data)

# Plot Brier Scores Over Time: Create line plots to show how the Brier score varies over time for each model.
ggplot(brier_data, aes(x = .eval_time, y = mean, color = model)) +
  geom_line() +
  labs(x = "Evaluation Time", y = "Brier Score", title = "Brier Score Comparison") +
  theme_minimal()

# Boxplots of Brier Scores: Create boxplots to show the distribution of Brier scores across folds and time points for each model.

ggplot(brier_data, aes(x = model, y = mean, fill = model)) +
  geom_boxplot() +
  labs(x = "Model", y = "Brier Score", title = "Boxplot of Brier Scores by Model") +
  theme_minimal()


# Summarize Brier scores
brier_summary <- brier_data %>%
  group_by(model) %>%
  summarise(mean_brier = mean(mean),
            sd_brier = sd(mean))
print(brier_summary)


# Create a line plot of Brier scores over time for each model:
ggplot(brier_data, aes(x = .eval_time, y = mean, color = model)) +
  geom_line() +
  geom_point() +
  labs(x = "Evaluation Time", y = "Brier Score", title = "Brier Score Over Time by Model") +
  theme_minimal()

```

```{r}
# Combine Brier and AUC ROC data
combined_data <- bind_rows(
  brier_data %>% mutate(metric = "Brier Score"),
  auc_data %>% mutate(metric = "AUC ROC")
)

ggplot(combined_data, aes(x = .eval_time, y = mean, color = model)) +
  geom_line() +
  facet_wrap(~ metric, scales = "free_y") +
  labs(x = "Evaluation Time", y = "Metric Value", title = "Brier Score and AUC ROC side by side") +
  theme_minimal()

```
