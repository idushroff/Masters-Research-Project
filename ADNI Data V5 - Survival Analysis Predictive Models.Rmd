---
title: "ADNI Data V2 - Survival Analysis Predictive Models"
output: html_document
date: "2023-03-29"
---

# ADNI Data V4 - Survival Analysis Predictive Models - same as version 3 except this time I am doing it for all the different recipes

## Install and load the relevant packages

```{r}

# install.packages("caret")
library(caret)

# install.packages("ranger")
library(ranger)

# install.packages("tidymodels")
library(tidymodels)

# install.packages("tidyverse")
library(tidyverse)

# install.packages("glmnet")
library(glmnet)

# install.packages("modeldatatoo")
library(modeldatatoo)

# install.packages("aorsf")
library(aorsf)

# install.packages("censored")
library(censored)

# install.packages("survival")
library(survival)

# install.packages("doParallel")
library(doParallel)

library(pROC) #for AUC calculation
# Install and load necessary packages
# install.packages("tidymodels")
library(tidymodels)

# install.packages("survival")
library(survival)

# install.packages("doParallel")
library(doParallel)

# Set up parallel processing
registerDoParallel()

```

Import dataset, Pre-process & set up cross validation

```{r}

# Import preprocessed data 
surv_df <- read.csv("preprocessed_data.csv") 
#View(surv_df)

# Remove rows with zero survival times
surv_df <- surv_df %>% filter(VISCODE > 0)

# Check event encoding
# table(surv_df$event)

# Create survival object
surv_df1 <- surv_df %>% 
  mutate(diagnosis_surv = Surv(VISCODE, event == "1")) %>%
  select(diagnosis_surv, everything())
# View(surv_df1)

# Define resampling scheme: repeated k-fold cross-validation
set.seed(403)
repeated_folds <- vfold_cv(surv_df1, v = 5, repeats = 3) # 5-fold cross-validation

# colnames(surv_df1)
```

Define all the Recipes

```{r}

# List of different recipes based on specified feature combinations, excluding features with 'dem'

recipes_list <- list(
  recipe_1 = recipe(diagnosis_surv ~ fam_hist_dad_ad + fam_hist_mum_ad + APOE4 + AGE + PTGENDER + PTEDUCAT + MMSE + mPACCtrailsB, data = surv_df1),
  recipe_2 = recipe(diagnosis_surv ~ fam_hist_dad_ad + fam_hist_mum_ad + APOE4 + AGE + PTGENDER + PTEDUCAT, data = surv_df1),
  recipe_3 = recipe(diagnosis_surv ~ fam_hist_dad_ad + fam_hist_mum_ad + APOE4, data = surv_df1),
  recipe_4 = recipe(diagnosis_surv ~ fam_hist_dad_ad + fam_hist_mum_ad, data = surv_df1),
  recipe_5 = recipe(diagnosis_surv ~ APOE4 + AGE + PTGENDER + PTEDUCAT + MMSE + mPACCtrailsB, data = surv_df1)
)

# Initialize list to store results for each recipe and model
results_list <- list()

# Define tuning grid for Cox model (penalty) and Random Forest (mtry, min_n)
cox_grid <- grid_regular(
  penalty(range = c(0.0001, 1)), # Regularization penalty for Cox model
  levels = 10                    # 10 values for penalty
)

rf_grid <- grid_regular(
  mtry(range = c(2, 5)),          # Number of features considered at each split (2 to 5)
  min_n(range = c(1, 10)),        # Minimum number of samples in a leaf (1 to 10)
  levels = 10                     # 10 values for each hyperparameter
)


# Iterate through recipes and run models for each
for (i in seq_along(recipes_list)) {
  # Select the current recipe
  current_recipe <- recipes_list[[i]]
  
  # Define models: Weibull, Cox, Random Forest
  # Weibull Model
  survreg_wflow <- workflow() %>% 
    add_recipe(current_recipe) %>% 
    add_model(survival_reg() %>% set_engine("survival") %>% set_mode("censored regression"))
  
  # Cox Proportional Hazards Model
  coxnet_wflow <- workflow() %>%
    add_recipe(current_recipe) %>%
    add_model(proportional_hazards(penalty = tune()) %>% set_engine("glmnet") %>% set_mode("censored regression"))

  # Random Forest Model
  oblique_wflow <- workflow() %>%
    add_recipe(current_recipe) %>%
    add_model(rand_forest(mtry = tune(), min_n = tune()) %>% set_engine("aorsf") %>% set_mode("censored regression"))
  
  # Define evaluation metrics for survival analysis
  survival_metrics <- metric_set(brier_survival_integrated, brier_survival, roc_auc_survival, concordance_survival)
  
  # Set evaluation time points for metrics
  evaluation_time_points <- seq(0, 144, 6)

  # Cross-validation resampling (for all models)
  set.seed(1)
  survreg_res <- fit_resamples(survreg_wflow, resamples = repeated_folds, metrics = survival_metrics, eval_time = evaluation_time_points, control = control_resamples(save_pred = TRUE))
  coxnet_res <- tune_grid(coxnet_wflow, resamples = repeated_folds, grid = cox_grid, metrics = survival_metrics, eval_time = evaluation_time_points, control = control_grid(save_pred = TRUE))
  oblique_res <- tune_grid(oblique_wflow, resamples = repeated_folds, grid = rf_grid, metrics = survival_metrics, eval_time = evaluation_time_points, control = control_grid(save_pred = TRUE))
  
  # Store the results for each model
  results_list[[paste0("Recipe_", i, "_Weibull")]] <- survreg_res
  results_list[[paste0("Recipe_", i, "_Cox")]] <- coxnet_res
  results_list[[paste0("Recipe_", i, "_RandomForest")]] <- oblique_res
}

```

```{r}


# Access results using results_list[['Recipe_1_Weibull']], etc.
# Function to extract and prepare metrics for plotting
prepare_plot_data <- function(result, model_name, recipe_name) {
  collect_metrics(result) %>%
    mutate(model = model_name, recipe = recipe_name)
}

# Initialize an empty data frame to store all metrics
all_metrics <- data.frame()

# Loop through results and extract metrics for each model and recipe
for (name in names(results_list)) {
  model_name <- str_extract(name, "Weibull|Cox|RandomForest")
  recipe_name <- str_extract(name, "Recipe_\\d+")
  
  metrics_data <- prepare_plot_data(results_list[[name]], model_name, recipe_name)
  all_metrics <- bind_rows(all_metrics, metrics_data)
}

# Plot Brier score and ROC AUC for all models and recipes
box_plot <- ggplot(all_metrics, aes(x = recipe, y = mean, fill = model)) +
  geom_boxplot() +
  facet_wrap(~.metric, scales = "free_y") +
  labs(title = "Model Comparison Across Recipes", x = "Recipe", y = "Metric Value") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))



# Create a custom legend for recipes
recipe_legend <- textGrob("Recipes: \n1. Family History + Genetics + Demographics + Cognition \n2. Family History + Genetics + Demographics \n3. Family History + Genetics \n4. Family History \n5. Demographics + Genetics + Cognition\n", 
                           gp = gpar(fontsize = 10), 
                           hjust = 0)

#################################

# Combine the box plot and the recipe legend
grid.arrange(box_plot, recipe_legend, ncol = 1, heights = c(3, 1))
```

-   Notes:

-   **Brier Survival** (Top left): This metric evaluates the accuracy of survival probability predictions. Lower values indicate better model performance. In this plot, we see the Cox model (red) has more variability in some recipes, while the RandomForest and Weibull models (green, blue) show less variation and seem to perform more consistently across recipes.

-   **Brier Survival Integrated** (Top right): This integrated Brier score is similar to the Brier survival score but integrates over time. Again, a lower value indicates better performance. In Recipe 1, the Cox model performs worse than the other two models, but the performance gap reduces in Recipes 2 and 3.

-   **Concordance Survival** (Bottom left): Concordance is used to evaluate the discriminative ability of the models. It ranges from 0.5 (random guessing) to 1 (perfect prediction). The Cox model shows the most variability in Recipe 1 but stabilizes in the other recipes. RandomForest and Weibull models have relatively stable concordance across recipes.

-   **ROC- AUC Survival** (Bottom right): This metric measures the area under the receiver operating characteristic curve. Higher values (closer to 1) indicate better model performance. The RandomForest and Weibull models perform similarly, while the Cox model has higher variability and performs worse, especially in Recipe 1
