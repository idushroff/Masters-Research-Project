---
title: "ADNI Data V2 - Binary Classification  Predictive Models"
output: html_document
date: "2023-03-29"
---

# ADNI Data Version 5 - Binary Classification Predictive Models - testing over specific hyperparameter values + trying one recipe over all models

## Install and load the relevant packages

```{r}

# install.packages("caret")
library(caret)

# install.packages("ranger")
library(ranger)

# install.packages("tidymodels")
library(tidymodels)

# install.packages("tidyverse")
library(tidyverse)

# install.packages("glmnet")
library(glmnet)

# install.packages("modeldatatoo")
library(modeldatatoo)

# install.packages("aorsf")
library(aorsf)

# install.packages("censored")
library(censored)

# install.packages("survival")
library(survival)

# install.packages("doParallel")
library(doParallel)

library(dplyr)

library(ggplot2)

library(gridExtra)
library(grid)

```

```{r}

# Import preprocessed data 
surv_df <- read.csv("preprocessed_data.csv")
# View(surv_df)

# Convert the event column to a factor
surv_df$event <- factor(surv_df$event, levels = c(0, 1), labels = c("No AD", "AD"))

# Convert PTGENDER to numeric (0 for Male, 1 for Female)
surv_df <- surv_df %>%
  mutate(SEX = ifelse(SEX == "Male", 0, 1))

# Set seed for reproducibility
set.seed(123)

# Define resampling scheme: repeated k-fold cross-validation
cv_folds <- vfold_cv(surv_df, v = 5, repeats = 3)

# List of different recipes based on specified feature combinations

# D = Demographics 
# F = Family History
# DF = Demographics + Family History 
# DGF = Demographics + Genetics + Family History 
# DGCF = Demographics + Genetics + Cognition + Family History
# DGC = Demographics + Genetics + Cognition

recipes_list <- list(
  D = recipe(event ~ AGE + SEX + EDU, data = surv_df)
  # Fh = recipe(event ~ FH, data = surv_df),
  # DFh = recipe(event ~ AGE + SEX + EDU + FH, data = surv_df),
  # DGFh = recipe(event ~ AGE + SEX + EDU + APOE4 + FH, data = surv_df),
  # DGCFh = recipe(event ~ AGE + SEX + EDU + APOE4 + MMSE + mPACCtrailsB + FH, data = surv_df1),
  # DGC = recipe(event ~ APOE4 + AGE + SEX + EDU + MMSE + mPACCtrailsB, data = surv_df)
)


# Initialize list to store results for each recipe and model
results_list <- list()

# # Define hyperparameters and initialize models for Logistic Regression, Random Forest, and XGBoost
# hyperparameter_table <- data.frame(
#   Algorithm = c("Logistic Regression", "Random Forest", "XGBoost"),
#   Hyperparameters = I(list(
#     list("No hyperparameters were tuned"),  # Logistic Regression
#     list("trees" = 1000,                    # Random Forest
#          "mtry" = c(3, 5, 7), 
#          "min_n" = c(5, 10, 20)), 
#     list("trees" = 200,                     # XGBoost
#          "learn_rate" = c(0.03, 0.08, 0.2, 0.5), 
#          "tree_depth" = c(2, 5))
#   ))
# )
# View the hyperparameter table
# print(hyperparameter_table)

# Define hyperparameter grids for Random Forest
rf_grid <- expand.grid(
  # trees = 1000,
  mtry = c(3, 5, 7),
  min_n = c(5, 10, 20)
)
print(rf_grid)
# Define hyperparameter grids for XGBoost
xgb_grid <- expand.grid(
  # trees = 200,
  learn_rate = c(0.03, 0.08, 0.2, 0.5),
  tree_depth = c(2, 5)
)
print(xgb_grid)
```

UPDATE - change recipe to feature set

```{r}

# Iterate through feature sets and run models for each
for (i in seq_along(recipes_list)) {
  current_recipe <- recipes_list[[i]]
  
  # Define models
  
  # Logistic Regression with alpha and l1_ratio tuning
  glm_wflow <- workflow() %>%
    add_recipe(current_recipe) %>%
    add_model(logistic_reg() %>%
                set_engine("glm") %>%
                set_mode("classification"))

  # ## Tuned Random Forest
  rf_wflow <- workflow() %>%
    add_recipe(current_recipe) %>%
    add_model(rand_forest(trees = 1000, 
                          mtry = tune(), 
                          min_n = tune()) %>%
                set_engine("ranger") %>%
                set_mode("classification"))

  # Tuned XGBoost
  xgb_wflow <- workflow() %>%
    add_recipe(current_recipe) %>%
    add_model(boost_tree(trees = 200, 
                         tree_depth = tune(), 
                         learn_rate = tune()) %>%
                set_engine("xgboost", objective = "binary:logistic") %>%
                set_mode("classification"))

  # Define evaluation metrics (ROC AUC)
  classification_metrics <- metric_set(accuracy, roc_auc, brier_class)

  # Fit models using resampling
  glm_res <- fit_resamples(glm_wflow, 
                           resamples = cv_folds, 
                           metrics = classification_metrics, 
                           control = control_resamples(save_pred = TRUE))
  
  rf_res <- tune_grid(rf_wflow, 
                      resamples = cv_folds, 
                      grid = rf_grid, 
                      metrics = classification_metrics, 
                      control = control_grid(save_pred = TRUE))
  
  xgb_res <- tune_grid(xgb_wflow, 
                       resamples = cv_folds, 
                       grid = xgb_grid, 
                       metrics = classification_metrics, 
                       control = control_grid(save_pred = TRUE))
  
  
  # Store the results for each model
  results_list[[paste0("Feature_Set_", names(recipes_list)[i], "_Logistic")]] <- glm_res
  results_list[[paste0("Feature_Set_", names(recipes_list)[i], "_RF")]] <- rf_res
  results_list[[paste0("Feature_Set_", names(recipes_list)[i], "_XGBoost")]] <- xgb_res
}


  
# Function to extract and prepare metrics for plotting
prepare_plot_data <- function(result, model_name, feature_set_name) {
  collect_metrics(result, summarize = FALSE) %>%
    mutate(Model = model_name, feature_set = feature_set_name)
}

# Initialize an empty data frame to store all metrics
all_metricsv5 <- data.frame()
all_metricsv5

# Loop through results and extract metrics for each model and feature set
for (name in names(results_list)) {
  model_name <- str_extract(name, "Logistic|RF|XGBoost")
  feature_set_name <- str_extract(name, "(?<=Feature_Set_)[^_]+")  # Now use the name directly as 'Feature_Set_D', 'Feature_Set_DF', etc.
  print(feature_set_name)
  metrics_data <- prepare_plot_data(results_list[[name]], model_name, feature_set_name)
  all_metricsv5 <- bind_rows(all_metricsv5, metrics_data)
}


# Summarize metrics for plotting
summary_metrics <- all_metricsv5 %>%
  group_by(feature_set, Model, .metric)

# Plot ROC AUC for all models and feature sets
BinaryAllModels_0 <- ggplot(summary_metrics, aes(x = feature_set, y = .estimate, fill = Model)) +
  geom_boxplot() +
  facet_wrap(~ .metric, scales = "free_y") +
  labs(title = "Binary Classification - Demographics Across All Model", 
       x = "Feature Set(s)", 
       y = "Metric Value") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  theme_light(base_size = 13) + 
  theme(legend.position = 'bottom')


# Print the box plot
print(BinaryAllModels_0)


# Custom legend (optional)
recipe_legend1 <- textGrob("Feature set: \n1. Demographics (D) = Age, Gender, Education \n2. Family History (Fh) = Mother or Father had Alzheimer's \n3. Genetics (G) = APOE4 \n4. Cognitive Tests (C) = MMSE, mPACCtrailsB \n", 
                           gp = gpar(fontsize = 10), 
                           hjust = 0)

# Combine the box plot and the legend
BinaryAllModels_1 <- grid.arrange(BinaryAllModels_0, recipe_legend1, ncol = 1, heights = c(3, 1))
print(BinaryAllModels_1)

# Custom legend (optional)
recipe_legend2 <- textGrob("Feature set: \n1. Demographics (D) \n2. Family History (Fh) \n3. Demographics + Family History (DFh) \n4. Demographics + Genetics + Family History (DGFh) \n5. Demographics + Genetics + Cognition + Family History (DGCFh) \n6. Demographics + Genetics + Cognition (DGC) \n",
                           gp = gpar(fontsize = 10),
                           hjust = 0)

# Combine the box plot and the legend
BinaryAllModels_2 <- grid.arrange(BinaryAllModels_0, recipe_legend2, ncol = 1, heights = c(3, 1))
print(BinaryAllModels_2)

# Save the updated plot
ggsave("Binary_All_Models_0.png", plot = BinaryAllModels_0, width = 10, height = 10)
ggsave("Binary_All_Models_1.png", plot = BinaryAllModels_1, width = 10, height = 10)
ggsave("Binary_All_Models_2.png", plot = BinaryAllModels_2, width = 10, height = 10)


```

```{r}


```
