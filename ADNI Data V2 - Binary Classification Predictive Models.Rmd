---
title: "ADNI Data V2 - Binary Classification  Predictive Models"
output: html_document
date: "2023-03-29"
---

# ADNI Data Version 2 - Binary Classification Predictive Models - streamlining the code and implementing k-fold cross validation so we have multiple train test splits and we do this in one go for all the different recipies

## Install and load the relevant packages

```{r}

# install.packages("caret")
library(caret)

# install.packages("ranger")
library(ranger)

# install.packages("tidymodels")
library(tidymodels)

# install.packages("tidyverse")
library(tidyverse)

# install.packages("glmnet")
library(glmnet)

# install.packages("modeldatatoo")
library(modeldatatoo)

# install.packages("aorsf")
library(aorsf)

# install.packages("censored")
library(censored)

# install.packages("survival")
library(survival)

# install.packages("doParallel")
library(doParallel)

library(dplyr)

library(ggplot2)
```

TUNED AND UNTUNED

```{r}

# Import preprocessed data 
surv_df <- read.csv("preprocessed_data.csv")

# Convert the event column to a factor
surv_df$event <- factor(surv_df$event, levels = c(0, 1), labels = c("No AD", "AD"))

# Convert PTGENDER to numeric (0 for Male, 1 for Female)
surv_df <- surv_df %>%
  mutate(PTGENDER = ifelse(PTGENDER == "Male", 0, 1))

# Set seed for reproducibility
set.seed(123)

# Define resampling scheme: repeated k-fold cross-validation
cv_folds <- vfold_cv(surv_df, v = 5, repeats = 3)

# List of different recipes based on specified feature combinations
recipes_list <- list(
  recipe_10 = recipe(event ~ APOE4 + AGE + PTGENDER + MMSE, data = surv_df),
  recipe_11 = recipe(event ~ APOE4 + AGE + PTGENDER, data = surv_df),
  recipe_12 = recipe(event ~ APOE4 + AGE, data = surv_df)
)

# Initialize list to store results for each recipe and model
results_list <- list()

# Iterate through recipes and run models for each
for (i in seq_along(recipes_list)) {
  current_recipe <- recipes_list[[i]]
  
  # Define models
  # Logistic Regression
  glm_wflow <- workflow() %>% 
    add_recipe(current_recipe) %>% 
    add_model(logistic_reg() %>% 
                set_engine("glm") %>% 
                set_mode("classification"))
  
  # Tuned Random Forest
  rf_tuned_wflow <- workflow() %>%
    add_recipe(current_recipe) %>%
    add_model(rand_forest(trees = 1000, #1000 trees in the forest
                          mtry = tune(), #No. of features to consider at each split
                          min_n = tune()) %>% #Min no. of data points in a leaf node
                set_engine("ranger") %>% 
                set_mode("classification"))

  # Untuned Random Forest
  rf_untuned_wflow <- workflow() %>%
    add_recipe(current_recipe) %>%
    add_model(rand_forest() %>% 
                set_engine("ranger") %>% 
                set_mode("classification"))
  
  # Tuned XGBoost
  xgb_tuned_wflow <- workflow() %>%
    add_recipe(current_recipe) %>%
    add_model(boost_tree(trees = 1000, # Only have 1000 trees
                         tree_depth = tune(), #Maximum depth of the tree
                         loss_reduction = tune(), #Minimum loss reduction (gamma)
                         mtry = tune(), #No. of features to consider at each split
                         min_n = tune(), #Minimum no. of data points in a leaf node
                         learn_rate = tune()) %>% #Learning rate (eta)
                set_engine("xgboost") %>% 
                set_mode("classification"))
  
  # Untuned XGBoost
  xgb_untuned_wflow <- workflow() %>%
    add_recipe(current_recipe) %>%
    add_model(boost_tree() %>% 
                set_engine("xgboost", objective = "binary:logistic") %>% 
                set_mode("classification"))
  
  # Define evaluation metrics (only ROC AUC)
  classification_metrics <- metric_set(roc_auc)

  # Fit models
  glm_res <- fit_resamples(glm_wflow, 
                           resamples = cv_folds, 
                           metrics = classification_metrics, 
                           control = control_resamples(save_pred = TRUE))
  
  rf_tuned_res <- tune_grid(rf_tuned_wflow, 
                            resamples = cv_folds, 
                            grid = 10, 
                            metrics = classification_metrics, 
                            control = control_grid(save_pred = TRUE))

  rf_untuned_res <- fit_resamples(rf_untuned_wflow, 
                                  resamples = cv_folds, 
                                  metrics = classification_metrics, 
                                  control = control_resamples(save_pred = TRUE))
  
  xgb_tuned_res <- tune_grid(xgb_tuned_wflow, 
                             resamples = cv_folds, 
                             grid = 10, 
                             metrics = classification_metrics, 
                             control = control_grid(save_pred = TRUE))
  
  xgb_untuned_res <- fit_resamples(xgb_untuned_wflow, 
                                   resamples = cv_folds, 
                                   metrics = classification_metrics, 
                                   control = control_resamples(save_pred = TRUE))
  
  # Store the results for each model
  results_list[[paste0("Recipe_", i, "_Logistic")]] <- glm_res
  results_list[[paste0("Recipe_", i, "_RF_Tuned")]] <- rf_tuned_res
  results_list[[paste0("Recipe_", i, "_RF_Untuned")]] <- rf_untuned_res
  results_list[[paste0("Recipe_", i, "_XGBoost_Tuned")]] <- xgb_tuned_res
  results_list[[paste0("Recipe_", i, "_XGBoost_Untuned")]] <- xgb_untuned_res
}

# Function to extract and prepare metrics for plotting
prepare_plot_data <- function(result, model_name, recipe_name) {
  collect_metrics(result) %>%
    mutate(model = model_name, recipe = recipe_name)
}

# Initialize an empty data frame to store all metrics
all_metrics <- data.frame()

# Loop through results and extract metrics for each model and recipe
for (name in names(results_list)) {
  model_name <- str_extract(name, "Logistic|RF_Tuned|RF_Untuned|XGBoost_Tuned|XGBoost_Untuned")
  recipe_name <- str_extract(name, "Recipe_\\d+")
  
  metrics_data <- prepare_plot_data(results_list[[name]], model_name, recipe_name)
  all_metrics <- bind_rows(all_metrics, metrics_data)
}

# Plot ROC AUC for all models and recipes
ggplot(all_metrics, aes(x = recipe, y = mean, fill = model)) +
  geom_boxplot() +
  facet_wrap(~.metric, scales = "free_y") +
  labs(title = "Model Comparison Across Recipes", x = "Recipe", y = "Metric Value") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```

# DENSITY PLOTS

```{r}
# Load necessary libraries
library(tidyverse)
library(tidymodels)

# Import preprocessed data 
surv_df <- read.csv("preprocessed_data.csv")

# Convert the event column to a factor
surv_df$event <- factor(surv_df$event, levels = c(0, 1), labels = c("No AD", "AD"))

# Convert PTGENDER to numeric (0 for Male, 1 for Female)
surv_df <- surv_df %>%
  mutate(PTGENDER = ifelse(PTGENDER == "Male", 0, 1))

# Set seed for reproducibility
set.seed(123)

# Define resampling scheme: repeated k-fold cross-validation
cv_folds <- vfold_cv(surv_df, v = 5, repeats = 3)

# List of different recipes based on specified feature combinations
recipes_list <- list(
  recipe_10 = recipe(event ~ APOE4 + AGE + PTGENDER + MMSE, data = surv_df),
  recipe_11 = recipe(event ~ APOE4 + AGE + PTGENDER, data = surv_df),
  recipe_12 = recipe(event ~ APOE4 + AGE, data = surv_df)
)

# Initialize list to store results for each recipe and model
results_list <- list()
predictions_list <- list()  # Initialize to store predictions

# Iterate through recipes and run models for each
for (i in seq_along(recipes_list)) {
  current_recipe <- recipes_list[[i]]
  
  # Define models
  # Logistic Regression
  glm_wflow <- workflow() %>% 
    add_recipe(current_recipe) %>% 
    add_model(logistic_reg() %>% set_engine("glm") %>% set_mode("classification"))
  
  # Tuned Random Forest
  rf_tuned_wflow <- workflow() %>% 
    add_recipe(current_recipe) %>% 
    add_model(rand_forest(trees = 1000, mtry = tune(), min_n = tune()) %>% set_engine("ranger") %>% set_mode("classification"))

  # Untuned Random Forest
  rf_untuned_wflow <- workflow() %>% 
    add_recipe(current_recipe) %>% 
    add_model(rand_forest() %>% set_engine("ranger") %>% set_mode("classification"))
  
  # Tuned XGBoost
  xgb_tuned_wflow <- workflow() %>% 
    add_recipe(current_recipe) %>% 
    add_model(boost_tree(trees = 1000, tree_depth = tune(), loss_reduction = tune(), mtry = tune(), min_n = tune(), learn_rate = tune()) %>% set_engine("xgboost") %>% set_mode("classification"))
  
  # Untuned XGBoost
  xgb_untuned_wflow <- workflow() %>% 
    add_recipe(current_recipe) %>% 
    add_model(boost_tree() %>% set_engine("xgboost", objective = "binary:logistic") %>% set_mode("classification"))
  
  # Define evaluation metrics (only ROC AUC)
  classification_metrics <- metric_set(roc_auc)

  # Fit models and collect predictions
  glm_res <- fit_resamples(glm_wflow, resamples = cv_folds, metrics = classification_metrics, control = control_resamples(save_pred = TRUE))
  rf_tuned_res <- tune_grid(rf_tuned_wflow, resamples = cv_folds, grid = 10, metrics = classification_metrics, control = control_grid(save_pred = TRUE))
  rf_untuned_res <- fit_resamples(rf_untuned_wflow, resamples = cv_folds, metrics = classification_metrics, control = control_resamples(save_pred = TRUE))
  xgb_tuned_res <- tune_grid(xgb_tuned_wflow, resamples = cv_folds, grid = 10, metrics = classification_metrics, control = control_grid(save_pred = TRUE))
  xgb_untuned_res <- fit_resamples(xgb_untuned_wflow, resamples = cv_folds, metrics = classification_metrics, control = control_resamples(save_pred = TRUE))
  
  # Store the results for each model
  results_list[[paste0("Recipe_", i, "_Logistic")]] <- glm_res
  results_list[[paste0("Recipe_", i, "_RF_Tuned")]] <- rf_tuned_res
  results_list[[paste0("Recipe_", i, "_RF_Untuned")]] <- rf_untuned_res
  results_list[[paste0("Recipe_", i, "_XGBoost_Tuned")]] <- xgb_tuned_res
  results_list[[paste0("Recipe_", i, "_XGBoost_Untuned")]] <- xgb_untuned_res
}

# Function to extract and prepare metrics for plotting
prepare_plot_data <- function(result, model_name, recipe_name) {
  collect_metrics(result) %>%
    mutate(model = model_name, recipe = recipe_name)
}

# Initialize an empty data frame to store all metrics
all_metrics <- data.frame()

# Loop through results and extract metrics for each model and recipe
for (name in names(results_list)) {
  model_name <- str_extract(name, "Logistic|RF_Tuned|RF_Untuned|XGBoost_Tuned|XGBoost_Untuned")
  recipe_name <- str_extract(name, "Recipe_\\d+")
  
  metrics_data <- prepare_plot_data(results_list[[name]], model_name, recipe_name)
  all_metrics <- bind_rows(all_metrics, metrics_data)
}

# Plot ROC AUC for all models and recipes
ggplot(all_metrics, aes(x = recipe, y = mean, fill = model)) +
  geom_boxplot() +
  facet_wrap(~.metric, scales = "free_y") +
  labs(title = "Model Comparison Across Recipes", x = "Recipe", y = "Metric Value") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Initialize an empty list to store predictions
predictions_list <- list()

# Loop through results to collect predictions for each model
for (name in names(results_list)) {
  # Collect predictions
  preds <- collect_predictions(results_list[[name]]) %>%
    mutate(model = str_extract(name, "Logistic|RF_Tuned|RF_Untuned|XGBoost_Tuned|XGBoost_Untuned"),
           recipe = str_extract(name, "Recipe_\\d+"))
  
  predictions_list[[name]] <- preds
}

# Combine all predictions into a single data frame
all_predictions <- bind_rows(predictions_list)

# Create density plots for predicted probabilities
ggplot(all_predictions, aes(x = .pred_AD, fill = model)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ recipe) + 
  labs(title = "Density of Predicted Probabilities by Model", 
       x = "Predicted Probability of AD", 
       y = "Density") +
  theme_minimal()

```

# FAMILY HISTORY RECIPE

```{r}
# Import preprocessed data 
surv_df <- read.csv("preprocessed_data.csv")

# Convert the event column to a factor
surv_df$event <- factor(surv_df$event, levels = c(0, 1), labels = c("No AD", "AD"))

# Convert PTGENDER to numeric (0 for Male, 1 for Female)
surv_df <- surv_df %>%
  mutate(PTGENDER = ifelse(PTGENDER == "Male", 0, 1))

# Set seed for reproducibility
set.seed(123)

# Define resampling scheme: repeated k-fold cross-validation
cv_folds <- vfold_cv(surv_df, v = 5, repeats = 3)

# List of different recipes based on specified feature combinations
recipes_list <- list(
  recipe_1 = recipe(event ~ fam_hist_dad_dem + fam_hist_dad_ad + fam_hist_mum_dem + fam_hist_mum_ad, data = surv_df),
  recipe_3 = recipe(event ~ fam_hist_dad_dem + fam_hist_dad_ad + fam_hist_mum_dem + fam_hist_mum_ad + APOE4 + AGE, data = surv_df)
  # recipe_10 = recipe(event ~ APOE4 + AGE + PTGENDER + MMSE, data = surv_df),
  # recipe_11 = recipe(event ~ APOE4 + AGE + PTGENDER, data = surv_df),
  # recipe_12 = recipe(event ~ APOE4 + AGE, data = surv_df)
)

# Initialize list to store results for each recipe and model
results_list <- list()

# Iterate through recipes and run models for each
for (i in seq_along(recipes_list)) {
  current_recipe <- recipes_list[[i]]
  
  # Define models
  # Logistic Regression
  glm_wflow <- workflow() %>% 
    add_recipe(current_recipe) %>% 
    add_model(logistic_reg() %>% 
                set_engine("glm") %>% 
                set_mode("classification"))
  
  # Tuned Random Forest
  rf_tuned_wflow <- workflow() %>%
    add_recipe(current_recipe) %>%
    add_model(rand_forest(trees = 1000, #1000 trees in the forest
                          mtry = tune(), #No. of features to consider at each split
                          min_n = tune()) %>% #Min no. of data points in a leaf node
                set_engine("ranger") %>% 
                set_mode("classification"))

  # Untuned Random Forest
  rf_untuned_wflow <- workflow() %>%
    add_recipe(current_recipe) %>%
    add_model(rand_forest() %>% 
                set_engine("ranger") %>% 
                set_mode("classification"))
  
  # Tuned XGBoost
  xgb_tuned_wflow <- workflow() %>%
    add_recipe(current_recipe) %>%
    add_model(boost_tree(trees = 1000, # Only have 1000 trees
                         tree_depth = tune(), #Maximum depth of the tree
                         loss_reduction = tune(), #Minimum loss reduction (gamma)
                         mtry = tune(), #No. of features to consider at each split
                         min_n = tune(), #Minimum no. of data points in a leaf node
                         learn_rate = tune()) %>% #Learning rate (eta)
                set_engine("xgboost") %>% 
                set_mode("classification"))
  
  # Untuned XGBoost
  xgb_untuned_wflow <- workflow() %>%
    add_recipe(current_recipe) %>%
    add_model(boost_tree() %>% 
                set_engine("xgboost", objective = "binary:logistic") %>% 
                set_mode("classification"))
  
  # Define evaluation metrics (only ROC AUC)
  classification_metrics <- metric_set(roc_auc)

  # Fit models
  glm_res <- fit_resamples(glm_wflow, 
                           resamples = cv_folds, 
                           metrics = classification_metrics, 
                           control = control_resamples(save_pred = TRUE))
  
  rf_tuned_res <- tune_grid(rf_tuned_wflow, 
                            resamples = cv_folds, 
                            grid = 10, 
                            metrics = classification_metrics, 
                            control = control_grid(save_pred = TRUE))

  rf_untuned_res <- fit_resamples(rf_untuned_wflow, 
                                  resamples = cv_folds, 
                                  metrics = classification_metrics, 
                                  control = control_resamples(save_pred = TRUE))
  
  xgb_tuned_res <- tune_grid(xgb_tuned_wflow, 
                             resamples = cv_folds, 
                             grid = 10, 
                             metrics = classification_metrics, 
                             control = control_grid(save_pred = TRUE))
  
  xgb_untuned_res <- fit_resamples(xgb_untuned_wflow, 
                                   resamples = cv_folds, 
                                   metrics = classification_metrics, 
                                   control = control_resamples(save_pred = TRUE))
  
  # Store the results for each model
  results_list[[paste0("Recipe_", i, "_Logistic")]] <- glm_res
  results_list[[paste0("Recipe_", i, "_RF_Tuned")]] <- rf_tuned_res
  results_list[[paste0("Recipe_", i, "_RF_Untuned")]] <- rf_untuned_res
  results_list[[paste0("Recipe_", i, "_XGBoost_Tuned")]] <- xgb_tuned_res
  results_list[[paste0("Recipe_", i, "_XGBoost_Untuned")]] <- xgb_untuned_res
}

# Function to extract and prepare metrics for plotting
prepare_plot_data <- function(result, model_name, recipe_name) {
  collect_metrics(result) %>%
    mutate(model = model_name, recipe = recipe_name)
}

# Initialize an empty data frame to store all metrics
all_metrics <- data.frame()

# Loop through results and extract metrics for each model and recipe
for (name in names(results_list)) {
  model_name <- str_extract(name, "Logistic|RF_Tuned|RF_Untuned|XGBoost_Tuned|XGBoost_Untuned")
  recipe_name <- str_extract(name, "Recipe_\\d+")
  
  metrics_data <- prepare_plot_data(results_list[[name]], model_name, recipe_name)
  all_metrics <- bind_rows(all_metrics, metrics_data)
}

# Plot ROC AUC for all models and recipes
ggplot(all_metrics, aes(x = recipe, y = mean, fill = model)) +
  geom_boxplot() +
  facet_wrap(~.metric, scales = "free_y") +
  labs(title = "Model Comparison Across Recipes", x = "Recipe", y = "Metric Value") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```

# TUNED Models ONLY 

```{r}

# Import preprocessed data 
surv_df <- read.csv("preprocessed_data.csv")

# Convert the event column to a factor
surv_df$event <- factor(surv_df$event, levels = c(0, 1), labels = c("No AD", "AD"))

# Convert PTGENDER to numeric (0 for Male, 1 for Female)
surv_df <- surv_df %>%
  mutate(PTGENDER = ifelse(PTGENDER == "Male", 0, 1))

# Set seed for reproducibility
set.seed(123)

# Define resampling scheme: repeated k-fold cross-validation
cv_folds <- vfold_cv(surv_df, v = 5, repeats = 3)

# List of different recipes based on specified feature combinations
recipes_list <- list(
  recipe_10 = recipe(event ~ APOE4 + AGE + PTGENDER + MMSE, data = surv_df),
  recipe_11 = recipe(event ~ APOE4 + AGE + PTGENDER, data = surv_df),
  recipe_12 = recipe(event ~ APOE4 + AGE, data = surv_df)
)

# Initialize list to store results for each recipe and model
results_list <- list()

# Iterate through recipes and run models for each
for (i in seq_along(recipes_list)) {
  current_recipe <- recipes_list[[i]]
  
  # Define models
  # Logistic Regression
  glm_wflow <- workflow() %>% 
    add_recipe(current_recipe) %>% 
    add_model(logistic_reg() %>% 
                set_engine("glm") %>% 
                set_mode("classification"))
  
  # Tuned Random Forest
  rf_tuned_wflow <- workflow() %>%
    add_recipe(current_recipe) %>%
    add_model(rand_forest(trees = 1000, #1000 trees in the forest
                          mtry = tune(), #No. of features to consider at each split
                          min_n = tune()) %>% #Min no. of data points in a leaf node
                set_engine("ranger") %>% 
                set_mode("classification"))

  
  # Tuned XGBoost
  xgb_tuned_wflow <- workflow() %>%
    add_recipe(current_recipe) %>%
    add_model(boost_tree(trees = 1000, # Only have 1000 trees
                         tree_depth = tune(), #Maximum depth of the tree
                         loss_reduction = tune(), #Minimum loss reduction (gamma)
                         mtry = tune(), #No. of features to consider at each split
                         min_n = tune(), #Minimum no. of data points in a leaf node
                         learn_rate = tune()) %>% #Learning rate (eta)
                set_engine("xgboost") %>% 
                set_mode("classification"))
  
  # Define evaluation metrics (only ROC AUC)
  classification_metrics <- metric_set(roc_auc)

  # Fit models
  glm_res <- fit_resamples(glm_wflow, 
                           resamples = cv_folds, 
                           metrics = classification_metrics, 
                           control = control_resamples(save_pred = TRUE))
  
  rf_tuned_res <- tune_grid(rf_tuned_wflow, 
                            resamples = cv_folds, 
                            grid = 10, 
                            metrics = classification_metrics, 
                            control = control_grid(save_pred = TRUE))
  
  xgb_tuned_res <- tune_grid(xgb_tuned_wflow, 
                             resamples = cv_folds, 
                             grid = 10, 
                             metrics = classification_metrics, 
                             control = control_grid(save_pred = TRUE))
  
  
  # Store the results for each model
  results_list[[paste0("Recipe_", i, "_Logistic")]] <- glm_res
  results_list[[paste0("Recipe_", i, "_RF_Tuned")]] <- rf_tuned_res
  results_list[[paste0("Recipe_", i, "_XGBoost_Tuned")]] <- xgb_tuned_res
}

# Function to extract and prepare metrics for plotting
prepare_plot_data <- function(result, model_name, recipe_name) {
  collect_metrics(result) %>%
    mutate(model = model_name, recipe = recipe_name)
}

# Initialize an empty data frame to store all metrics
all_metrics <- data.frame()

# Loop through results and extract metrics for each model and recipe
for (name in names(results_list)) {
  model_name <- str_extract(name, "Logistic|RF_Tuned|RF_Untuned|XGBoost_Tuned|XGBoost_Untuned")
  recipe_name <- str_extract(name, "Recipe_\\d+")
  
  metrics_data <- prepare_plot_data(results_list[[name]], model_name, recipe_name)
  all_metrics <- bind_rows(all_metrics, metrics_data)
}

# Plot ROC AUC for all models and recipes
ggplot(all_metrics, aes(x = recipe, y = mean, fill = model)) +
  geom_boxplot() +
  facet_wrap(~.metric, scales = "free_y") +
  labs(title = "Model Comparison Across Recipes", x = "Recipe", y = "Metric Value") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))



```
