---
title: "ADNI Data V2 - Survival Analysis Predictive Models"
output: html_document
date: "2023-03-29"
---

# ADNI Data Version 6 - Survival Analysis Predictive Models - testing over specific hyperparameter values + trying multiple recipes for best model

## Install and load the relevant packages

```{r}

# install.packages("caret")
library(caret)

# install.packages("ranger")
library(ranger)

# install.packages("tidymodels")
library(tidymodels)

# install.packages("tidyverse")
library(tidyverse)

# install.packages("glmnet")
library(glmnet)

# install.packages("modeldatatoo")
library(modeldatatoo)

# install.packages("aorsf")
library(aorsf)

# install.packages("censored")
library(censored)

# install.packages("survival")
library(survival)

# install.packages("doParallel")
library(doParallel)

library(pROC) #for AUC calculation
# Install and load necessary packages
# install.packages("tidymodels")
library(tidymodels)

# install.packages("survival")
library(survival)

# install.packages("doParallel")
library(doParallel)

# Set up parallel processing
registerDoParallel()

```

Import dataset, Pre-process & set up cross validation

```{r}

# Import preprocessed data 
surv_df <- read.csv("preprocessed_data.csv") 
# View(surv_df)

# Create survival object
surv_df1 <- surv_df %>% 
  mutate(diagnosis_surv = Surv(VISCODE, event == "1")) %>%
  select(diagnosis_surv, everything())
# View(surv_df1)

# Define resampling scheme: repeated k-fold cross-validation
set.seed(403)
repeated_folds <- vfold_cv(surv_df1, v = 5, repeats = 3) # 5-fold cross-validation

# colnames(surv_df1)

# List of different recipes based on specified feature combinations

# D = Demographics 
# F = Family History
# DF = Demographics + Family History 
# DGF = Demographics + Genetics + Family History 
# DGCF = Demographics + Genetics + Cognition + Family History
# DGC = Demographics + Genetics + Cognition

recipes_list <- list(
  D = recipe(diagnosis_surv ~ AGE + SEX + EDU, data = surv_df1),
  Fh = recipe(diagnosis_surv ~ FH, data = surv_df1),
  DFh = recipe(diagnosis_surv ~ AGE + SEX + EDU + FH, data = surv_df1),
  DGFh = recipe(diagnosis_surv ~ AGE + SEX + EDU + APOE4 + FH, data = surv_df1),
  DGCFh = recipe(diagnosis_surv ~ AGE + SEX + EDU + APOE4 + MMSE + mPACCtrailsB + FH, data = surv_df1),
  DGC = recipe(diagnosis_surv ~ APOE4 + AGE + SEX + EDU + MMSE + mPACCtrailsB, data = surv_df1)
)

# Initialize list to store results for each recipe and model
results_list <- list()

# Define tuning grid for Cox model (regularization penalty)
cox_grid <- grid_values(
  penalty = c(0.01, 0.1, 1, 10, 100)  # Specific values for regularization penalty
)


# Define tuning grid for Random Forest
rf_grid <- grid_values(
  max_depth = c(0, 2, 5, 10),            # Maximum depth of the tree
  min_samples_split = c(2, 5, 10),       # Minimum samples required to split a node
  min_n = c(1, 2, 4)                     # Minimum samples in a leaf node
)
```

# Define all the Recipes

```{r}


# Iterate through recipes and run models for each
for (i in seq_along(recipes_list)) {
  # Select the current recipe
  current_recipe <- recipes_list[[i]]
  
  # Define models: Weibull, Cox, Random Forest
  # Weibull Model
  survreg_wflow <- workflow() %>% 
    add_recipe(current_recipe) %>% 
    add_model(survival_reg() %>% 
                set_engine("survival") %>% 
                set_mode("censored regression"))
  
  # Cox Proportional Hazards Model
  coxnet_wflow <- workflow() %>%
    add_recipe(current_recipe) %>%
    add_model(proportional_hazards(penalty = tune()) %>% 
                set_engine("glmnet") %>% 
                set_mode("censored regression"))

  # Random Forest Model
  oblique_wflow <- workflow() %>%
    add_recipe(current_recipe) %>%
    add_model(rand_forest(mtry = tune(), min_n = tune()) %>% 
                set_engine("aorsf") %>% 
                set_mode("censored regression"))
  
  # Define evaluation metrics for survival analysis
  survival_metrics <- metric_set(brier_survival_integrated, 
                                 roc_auc_survival, 
                                 concordance_survival)
  
  # Set evaluation time points for metrics
  evaluation_time_points <- seq(0, 144, 6)

  # Cross-validation resampling (for all models)
  set.seed(1)
  survreg_res <- fit_resamples(survreg_wflow, 
                               resamples = repeated_folds, 
                               metrics = survival_metrics, 
                               eval_time = evaluation_time_points, 
                               control = control_resamples(save_pred = TRUE))
  
  coxnet_res <- tune_grid(coxnet_wflow, 
                          resamples = repeated_folds, 
                          grid = cox_grid, 
                          metrics = survival_metrics, 
                          eval_time = evaluation_time_points, 
                          control = control_grid(save_pred = TRUE))
  
  oblique_res <- tune_grid(oblique_wflow, 
                           resamples = repeated_folds, 
                           grid = rf_grid, 
                           metrics = survival_metrics, 
                           eval_time = evaluation_time_points, 
                           control = control_grid(save_pred = TRUE))
  
  # Store the results for each model
  results_list[[paste0("Recipe_", i, "_Weibull")]] <- survreg_res
  results_list[[paste0("Recipe_", i, "_Cox")]] <- coxnet_res
  results_list[[paste0("Recipe_", i, "_RandomForest")]] <- oblique_res
}

```

```{r}


# Access results using results_list[['Recipe_1_Weibull']], etc.
# Function to extract and prepare metrics for plotting
prepare_plot_data <- function(result, model_name, recipe_name) {
  collect_metrics(result) %>%
    mutate(Model = model_name, recipe = recipe_name)
}

# Initialize an empty data frame to store all metrics
all_metrics <- data.frame()

# Loop through results and extract metrics for each model and recipe
for (name in names(results_list)) {
  model_name <- str_extract(name, "Weibull|Cox|RandomForest")
  recipe_name <- str_extract(name, "(?<=Feature_Set_)[^_]+")  
  metrics_data <- prepare_plot_data(results_list[[name]], model_name, recipe_name)
  all_metrics <- bind_rows(all_metrics, metrics_data)
}


# Plot Brier score and ROC AUC for all models and recipes
Survival_X_All_0 <- ggplot(all_metrics, aes(x = recipe, y = mean, fill = Model)) +
  geom_boxplot() +
  facet_wrap(~.metric, scales = "free_y") +
  labs(title = "Survival Analysis - Comparison of Feature Sets Across Best Model", x = "Feature Set(s)", y = "Metric Value") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  theme_light(base_size = 13) + 
  theme(legend.position = 'bottom')

print(Survival_X_All_0)


# Custom legend (optional)
# recipe_legend1 <- textGrob("Feature set: \n1. Demographics (D) = Age, Gender, Education \n2. Family History (Fh) = Mother or Father had Alzheimer's \n3. Genetics (G) = APOE4 \n4. Cognitive Tests (C) = MMSE, mPACCtrailsB \n", 
                           # gp = gpar(fontsize = 10), 
                           # hjust = 0)

# Combine the box plot and the legend
# Survival_X_All_1 <- grid.arrange(Survival_X_All_0, recipe_legend1, ncol = 1, heights = c(3, 1))
# print(Survival_X_All_1)

# Custom legend (optional)
# recipe_legend2 <- textGrob("Feature set: \n1. Demographics (D) \n2. Family History (DFh) \n3. Demographics + Family History (DFh) \n4. Demographics + Genetics + Family History (DGFh) \n5. Demographics + Genetics + Cognition + Family History (DGCFh) \n6. Demographics + Genetics + Cognition (DGC) \n",
                           # gp = gpar(fontsize = 10),
                           # hjust = 0)

# Combine the box plot and the legend
# Survival_X_All_2 <- grid.arrange(Survival_X_All_0, recipe_legend2, ncol = 1, heights = c(3, 1))
# print(Survival_X_All_2)

# Save the updated plot
ggsave("Survival_X_All_0.png", plot = Survival_X_All_0, width = 10, height = 10)
# ggsave("Survival_X_All_1.png", plot = Survival_X_All_1, width = 10, height = 10)
# ggsave("Survival_X_All_2.png", plot = Survival_X_All_2, width = 10, height = 10)
```

-   Notes:

-   **Brier Survival** (Top left): This metric evaluates the accuracy of survival probability predictions. Lower values indicate better model performance. In this plot, we see the Cox model (red) has more variability in some recipes, while the RandomForest and Weibull models (green, blue) show less variation and seem to perform more consistently across recipes.

-   **Brier Survival Integrated** (Top right): This integrated Brier score is similar to the Brier survival score but integrates over time. Again, a lower value indicates better performance. In Recipe 1, the Cox model performs worse than the other two models, but the performance gap reduces in Recipes 2 and 3.

-   **Concordance Survival** (Bottom left): Concordance is used to evaluate the discriminative ability of the models. It ranges from 0.5 (random guessing) to 1 (perfect prediction). The Cox model shows the most variability in Recipe 1 but stabilizes in the other recipes. RandomForest and Weibull models have relatively stable concordance across recipes.

-   **ROC- AUC Survival** (Bottom right): This metric measures the area under the receiver operating characteristic curve. Higher values (closer to 1) indicate better model performance. The RandomForest and Weibull models perform similarly, while the Cox model has higher variability and performs worse, especially in Recipe 1
