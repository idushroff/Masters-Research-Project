---
title: "ADNI Data V1 - Survival Analysis Predictive Models"
output: html_document
date: "2023-03-29"
---

# ADNI Data V1 - Survival Analysis Predictive Models - No K-fold Cross validation

## Install and load the relevant packages

```{r}

# Install and load the caret package, which provides a set of functions for training and plotting classification and regression models.
# install.packages("caret")
library(caret)


# Install and load the ranger package, which provides an efficient implementation of random forests.
# install.packages("ranger")
library(ranger)

# Install and load the tidymodels package, which provides a framework for modeling and machine learning.
# install.packages("tidymodels")
library(tidymodels)

# library(parsnip) # Install the parsnip package, for modeling. Useful because it provides a consistent interface to many different types of models.
# library(rsample) # For resampling methods; data splitting and resampling methods, such as cross-validation and bootstrapping.
# library(recipes) # For preprocessing and feature engineering tasks, such as data transformation and variable selection.
# library(workflows) # Provides a framework for creating and managing modeling workflows, allowing you to define and execute a series of preprocessing, modeling, and evaluation steps in a coherent manner.
# library(yardstick) # Install and load the yardstick package, which provides tools for evaluating models with tidy data principles.


# Install and load the tidyverse package, which is a collection of packages for data manipulation and visualization.
# install.packages("tidyverse")
library(tidyverse)

# readr: For reading CSV files
# dplyr: For data manipulation
# ggplot2:For plots and graphs
# tidyr: For tidying and reshaping data into a tidy format.
# purrr: For functional programming and working with lists and vectors.
# tibble: For creating and working with modern data frames.
# stringr: For string manipulation and text processing.
# forcats: For working with categorical data and factors.
# lubridate: For working with dates and times.
# magrittr: For creating expressive pipelines using the pipe operator %>%.
# rlang: For advanced manipulation and programming with R expressions.


# This package implements the elastic net regularization method for fitting generalized linear models (GLMs) and Cox proportional hazards models. Elastic net is a regularization technique that combines both L1 (lasso) and L2 (ridge) penalties to overcome some of the limitations of these individual methods, particularly in high-dimensional data settings. It's widely used for feature selection and regularization in regression and survival analysis.
# install.packages("glmnet")
library(glmnet)

# This package provides functions for creating synthetic datasets for modeling and simulation purposes. Synthetic datasets are artificially generated data that mimic the characteristics of real-world data. They are useful for testing models, evaluating algorithms, and conducting sensitivity analyses without relying on actual data, which may be limited or sensitive.
# install.packages("modeldatatoo")
library(modeldatatoo)

# This package stands for "Adaptive Orthogonal Random Survival Forests". It provides tools for building survival models using random forests with the adaptive orthogonal direction method. Random forests are an ensemble learning method for classification, regression, and survival analysis, and this package offers enhancements specifically for survival analysis.
# install.packages("aorsf")
library(aorsf)

# This package provides functions for analyzing survival data with censoring. Survival analysis deals with time-to-event data, where the "event" of interest could be death, failure, or any other predefined endpoint. Censoring occurs when the event of interest is not observed for some subjects within the study period. This package offers various methods and tools for handling censored survival data.
# install.packages("censored")
library(censored)


# Install packages for plotting survival analysis curves
# install.packages("survival")
library(survival)

# For parallel processing
# install.packages("doParallel")
library(doParallel)
```

# SURVIVAL ANALYSIS MODEL

# 1. Censored regression Weibull distribution

Load the Dataset and spit into training validation and test set:

```{r}
 # Import preprocessed data 
surv_df <- read.csv("preprocessed_data.csv") 
# View(surv_df)

# In the dataset, we can see the time to event in the VISCODE column as well as the status of the participant. When the time to event for a participant with the status "No AD" is labeled as censored, it means that the event of interest (such as progression to Alzheimer's disease) did not occur within the observed time period. This could be due to various reasons; the study ending before the event could happen to that participant, or simply because the event has not yet occurred at the time of data collection. 

# Remove rows with zero survival times
surv_df <- surv_df %>% filter(VISCODE > 0)

# Check event encoding
# table(surv_df$event)

#   0   1 
# 954 380 

surv_df1 <- surv_df %>% 
  mutate(diagnosis_surv = Surv(VISCODE, event == "1")) %>%
  select(diagnosis_surv, everything())
# View(surv_df1)

# For our resampling strategy, let’s use a 3-way split into training, validation, and test set.
set.seed(403)

data_split <- initial_validation_split(surv_df1)
train_data <- training(data_split)

```

```{r}
# First, let’s pull out the training data and have a brief look at the response using a Kaplan-Meier curve.

survfit(diagnosis_surv ~ 1, data = train_data) %>% plot(main = "Kaplan-Meier Curve for AD Diagnosis", 
       xlab = "Time (VISCODE)", 
       ylab = "Survival Probability")
# We can see that the majority of paticipants are not diagnosed with AD even after 140 viscodes.

```

Defining the different recipes:

```{r}

# Define a recipe for preprocessing the data, using 'AGE' and 'APOE4' to predict 'diagnosis_surv'

surv_recipe <- recipe(diagnosis_surv ~ AGE + APOE4 , data = train_data)

# Define a recipe for preprocessing the data using cognitive test scores and education level to predict 'diagnosis_surv'

# surv_recipe <- recipe(diagnosis_surv ~ mPACCtrailsB + MMSE + PTEDUCAT, data = train_data)

# Define a recipe for preprocessing the data using familial history predictors to predict 'diagnosis_surv'

# surv_recipe <- recipe(diagnosis_surv ~ fam_hist_dad_dem + fam_hist_dad_ad + fam_hist_mum_dem + fam_hist_mum_ad, data = train_data)


```

Define the parametric survival model assuming a weibull distribution and corresponding workflow:

```{r}

# The censored package includes parametric, semi-parametric, and tree-based models for this type of analysis. To start, we are fitting a parametric survival model with the default of assuming a Weibull distribution on the time to disposition. We’ll explore the more flexible models once we have a sense of how well this more restrictive model performs on this dataset.

survreg_spec <- survival_reg() %>% 
  set_engine("survival") %>% 
  set_mode("censored regression")


# We combine the recipe and the model into a workflow. This allows us to easily resample the model because all preprocessing steps are applied to the training set and the validation set for us.

survreg_wflow <- workflow() %>% 
  add_recipe(surv_recipe) %>% 
  add_model(survreg_spec)
```

Fit the model:

```{r}

# To fit and evaluate the model, we need the training and validation sets. While we can access them each on their own, validation_set() extracts them both, in a manner that emulates a single resample of the data. This enables us to use fit_resamples() and other tuning functions in the same way as if we had used some other resampling scheme (such as cross-validation).

surv_rset <- validation_set(data_split)

# We are calculating several performance metrics: the Brier score, its integrated version, the area under the ROC curve, and the concordance index. Note that all of these are used in a version tailored to survival analysis. The concordance index uses the predicted event time to measure the model’s ability to rank the observations correctly. The Brier score and the ROC curve use the predicted probability of survival at a given time. We evaluate these metrics every 30 days up to 300 days, as provided in the eval_time argument. The Brier score is a measure of the accuracy of the predicted probabilities, while the ROC curve is a measure of the model’s ability to discriminate between events and non-events at the given time point. Because these metrics are defined “at a given time,” they are also referred to as dynamic metrics.

survival_metrics <- metric_set(brier_survival_integrated, brier_survival,
                               roc_auc_survival, concordance_survival)

evaluation_time_points <- seq(0, 144, 6)

survreg_res <- fit_resamples(
  survreg_wflow,
  resamples = surv_rset,
  metrics = survival_metrics,
  eval_time = evaluation_time_points, 
  control = control_resamples(save_pred = TRUE)
)

collect_predictions(survreg_res)

# The structure of survival model predictions is slightly different from classification and regression model predictions:
preds <- collect_predictions(survreg_res)
preds

# The predicted survival time is in the .pred_time column and the predicted survival probabilities are in the .pred list column.
preds$.pred[[6]]
# For each observation, .pred contains a tibble with the evaluation time .eval_time and the corresponding survival probability .pred_survival. The column .weight_censored contains the weights used in the calculation of the dynamic performance metrics.


```

```{r}

# Plot the ROC AUC
collect_metrics(survreg_res) %>%
  filter(.metric == "roc_auc_survival") %>%
  ggplot(aes(.eval_time, mean)) +
  geom_line() +
  labs(x = "Evaluation Time (VISCODE)", y = "Area Under the ROC Curve") +
  ggtitle("Weibull Distribution - AUC ROC Curve Over Time")

```

Interpretation of Area under the ROC curve plot: The ROC curve is a measure of the model's ability to discriminate between events and non-events at the given time point.

We can discriminate between events and non-events pretty well towards the study? ???

```{r}

# Plot the Brier score
collect_metrics(survreg_res) %>%
  filter(.metric == "brier_survival") %>%
  ggplot(aes(.eval_time, mean)) +
  geom_line() +
  labs(x = "Evaluation Time", y = "Brier Score")+
  ggtitle(" weibull Distribution - Birer Score Over Time")


```

\# Interpretation of Brier Score Plot:

The Brier score is a measure of the accuracy of the predicted probabilities.

At the beginning of the evaluation period (near time 0), the Brier score is low, indicating high accuracy in the short-term predictions. This is expected because there are likely few events (deaths or disease progressions) early on, so the survival probabilities are close to 1, leading to low Brier scores.

As time progresses, the Brier score increases. This suggests that the accuracy of the survival predictions decreases over time. This could be due to a number of factors such as more events occurring, making predictions harder, or the model not capturing long-term survival trends well.

The score fluctuates over time, which indicates variability in the model's accuracy at different time points. This can occur if the number of events changes significantly at different times or if the model's assumptions do not hold uniformly across all time points.

Towards the end of the evaluation period, the Brier score spikes, indicating poor predictive accuracy. This could be due to a small number of subjects remaining in the study, leading to higher uncertainty and less reliable predictions.

```{r}
collect_metrics(survreg_res) %>% 
  filter(.metric == "brier_survival_integrated")

```

# Lets try more models:

```{r}


# 1. Oblique Random Forest Model (oblique_spec) (specifically, an oblique random - forest for survival analysis). - is a flexible, non-parametric model that doesn't assume any specific underlying distribution of the survival times. It uses random forests to model the relationship between covariates and survival outcomes.

oblique_spec <- rand_forest(mtry = tune(), min_n = tune()) %>% 
  set_engine("aorsf") %>% 
  set_mode("censored regression")

oblique_wflow <- workflow() %>% 
  add_recipe(surv_recipe) %>% 
  add_model(oblique_spec)

# 2. Penalized Cox Proportional Hazards Model (coxnet_spec) - is a semi-parametric model that assumes the hazards are proportional over time. The penalty term helps handle multicollinearity and reduce model complexity.


coxnet_spec <- proportional_hazards(penalty = tune()) %>% 
  set_engine("glmnet") %>% 
  set_mode("censored regression")

coxnet_wflow <- workflow() %>% 
  add_recipe(surv_recipe) %>% 
  add_model(coxnet_spec)
```

```{r}
set.seed(1)
oblique_res <- tune_grid(
  oblique_wflow,
  resamples = surv_rset,
  grid = 10,
  metrics = survival_metrics,
  eval_time = evaluation_time_points, 
  control = control_grid(save_workflow = TRUE)
)
#> i Creating pre-processing data to finalize unknown parameter: mtry

set.seed(1)
coxnet_res <- tune_grid(
  coxnet_wflow,
  resamples = surv_rset,
  grid = 10,
  metrics = survival_metrics,
  eval_time = evaluation_time_points, 
  control = control_grid(save_workflow = TRUE)
)


```

# 

So do any of these models perform better than the parametric survival model?

```{r}
show_best(oblique_res, metric = "brier_survival_integrated", n = 5)
#> # A tibble: 5 × 9
#>    mtry min_n .metric         .estimator .eval_time   mean     n std_err .config
#>   <int> <int> <chr>           <chr>           <dbl>  <dbl> <int>   <dbl> <chr>  
#> 1     8    16 brier_survival… standard           NA 0.0468     1      NA Prepro…
#> 2     4     6 brier_survival… standard           NA 0.0469     1      NA Prepro…
#> 3     6    23 brier_survival… standard           NA 0.0469     1      NA Prepro…
#> 4     7    26 brier_survival… standard           NA 0.0470     1      NA Prepro…
#> 5     9    38 brier_survival… standard           NA 0.0471     1      NA Prepro…

show_best(coxnet_res, metric = "brier_survival_integrated", n = 5)
#> # A tibble: 5 × 8
#>         penalty .metric       .estimator .eval_time   mean     n std_err .config
#>           <dbl> <chr>         <chr>           <dbl>  <dbl> <int>   <dbl> <chr>  
#> 1 0.00750       brier_surviv… standard           NA 0.0496     1      NA Prepro…
#> 2 0.000000262   brier_surviv… standard           NA 0.0506     1      NA Prepro…
#> 3 0.0000000591  brier_surviv… standard           NA 0.0506     1      NA Prepro…
#> 4 0.00000000200 brier_surviv… standard           NA 0.0506     1      NA Prepro…
#> 5 0.0000588     brier_surviv… standard           NA 0.0506     1      NA Prepro…
```

The best regularized Cox model performs a little better than the parametric survival model, with an integrated Brier score of 0.1894 compared to 0.1886 for the W parametric model. The random forest performs slightly better with an integrated Brier score of 0.1906.

THE FINAL MODEL:

We chose the random forest model as the final model. So let's finalize the workflow by replacing the `tune()` placeholders with the best hyperparameters.

```{r}

param_best <- select_best(oblique_res, metric = "brier_survival_integrated")

last_oblique_wflow <- finalize_workflow(oblique_wflow, param_best)
```

We can now fit the final model on the training data and evaluate it on the test data.

```{r}
set.seed(2)
last_oblique_fit <- last_fit(
  last_oblique_wflow, 
  split = data_split,
  metrics = survival_metrics,
  eval_time = evaluation_time_points, 
)

collect_metrics(last_oblique_fit) %>% 
  filter(.metric == "brier_survival_integrated")

```

The Brier score across the different evaluation time points in the test set is less than the one we observe from the validation set. Which is expected. We wouldn't expect the model to perform better than how it does on the validation set however it would have been better if it had a brier score similar to the validation set.

```{r}

brier_val <- collect_metrics(oblique_res) %>% 
  filter(.metric == "brier_survival") %>% 
  filter(mtry == param_best$mtry, min_n == param_best$min_n) %>% 
  mutate(Data = "Validation") 
brier_test <- collect_metrics(last_oblique_fit) %>% 
  filter(.metric == "brier_survival") %>% 
  mutate(Data = "Testing") %>% 
  rename(mean = .estimate)
bind_rows(brier_val, brier_test) %>% 
  ggplot(aes(.eval_time, mean, col = Data)) + 
  geom_line() + 
  labs(x = "Evaluation Time", y = "Brier Score")
```

To finish, we can extract the fitted workflow to either predict directly on new data or deploy the model.

\# see -\> <https://www.tidymodels.org/learn/statistics/survival-case-study/#data-splitting-and-resampling>
